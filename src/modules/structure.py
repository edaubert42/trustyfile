"""
Module E: PDF Structure Analysis

This module analyzes the internal structure of a PDF to detect manipulation.

What we check:
1. Incremental updates - Each edit adds a revision to the PDF
2. Deleted objects - Content removed but still in file (ghost data)
3. JavaScript - Very suspicious in invoices/certificates
4. Annotations - Hidden comments or notes
5. Multiple versions - Sign of editing

Why structure matters for fraud detection:
- A PDF generated by a billing system has ONE version
- A PDF edited manually has MULTIPLE versions (incremental updates)
- Deleted content can be recovered from the file
- JavaScript in an invoice is almost always malicious

Technical background:
PDF files are "append-only" by default. When you edit a PDF:
1. Original content stays in the file
2. New content is appended at the end
3. A new "xref" table points to the updated objects
4. The file grows with each edit

This means we can detect:
- How many times the PDF was modified
- What objects were deleted (but still present)
- If content was added after initial creation
"""

import re
import logging
import difflib
from dataclasses import dataclass
import fitz  # PyMuPDF

from src.models import Flag, ModuleResult
from src.extractors.pdf_extractor import PDFData
from src.modules.metadata import check_dates

logger = logging.getLogger(__name__)


# =============================================================================
# PDF MODIFICATION HISTORY FUNCTIONS
# =============================================================================

def find_eof_positions(raw_bytes: bytes) -> list[int]:
    """
    Find the byte position of every %%EOF marker in a PDF file.

    Each %%EOF marks the end of a PDF version. A clean PDF has 1 %%EOF.
    Each incremental update (edit) adds another %%EOF.

    We return the position AFTER the %%EOF + newline, so that:
        raw_bytes[:positions[0]] = version 1 (original)
        raw_bytes[:positions[1]] = version 2 (first edit)
        etc.

    Args:
        raw_bytes: The raw bytes of the PDF file

    Returns:
        List of byte positions, one per version.
        Example: [1234, 5678, 9012] means 3 versions.

    Example:
        >>> content = b'%PDF-1.4 ... %%EOF\\n ... edit ... %%EOF\\n'
        >>> positions = find_eof_positions(content)
        >>> len(positions)  # 2 versions
        2
        >>> original = content[:positions[0]]  # First version
    """
    positions = []
    # The %%EOF marker — we search for it as bytes
    marker = b'%%EOF'

    # Start searching from the beginning
    start = 0
    while True:
        # find() returns -1 if not found
        pos = raw_bytes.find(marker, start)
        if pos == -1:
            break  # No more %%EOF markers

        # We want the position AFTER the marker + any trailing newline
        # so that slicing raw_bytes[:end_pos] gives a complete version
        end_pos = pos + len(marker)

        # Skip trailing whitespace/newlines after %%EOF
        # (PDF spec allows \n, \r\n, or \r after %%EOF)
        while end_pos < len(raw_bytes) and raw_bytes[end_pos:end_pos + 1] in (b'\n', b'\r'):
            end_pos += 1

        positions.append(end_pos)

        # Continue searching after this marker
        start = end_pos

    return positions


def extract_text_from_content_stream(stream_bytes: bytes) -> str:
    """
    Parse a decompressed PDF content stream to extract visible text.

    PDF content streams contain drawing operators. Text is rendered by operators
    like Tj (show string), TJ (show array with kerning), ' and " (next line + show).

    Text strings in PDF are enclosed in parentheses: (Hello World)
    Special characters are escaped: \\( \\) \\\\

    For the TJ operator, the array mixes strings and numbers:
        [(He) -10 (llo)] TJ  →  "Hello"
    The numbers are kerning adjustments (spacing) — we ignore them.

    Args:
        stream_bytes: Decompressed content stream bytes (from xref_stream())

    Returns:
        Extracted text as a single string, with spaces between text chunks
        and newlines between text blocks.

    Example:
        >>> stream = b'BT (Hello) Tj (World) Tj ET'
        >>> extract_text_from_content_stream(stream)
        'Hello World'
    """
    try:
        # Decode bytes to string — content streams are usually ASCII/Latin-1
        text = stream_bytes.decode('latin-1', errors='replace')
    except Exception:
        return ""

    extracted_parts = []

    # Regex to find PDF string literals inside parentheses: (some text)
    # Handles escaped parens \( \) and escaped backslash \\
    # The pattern matches: open paren, then any sequence of:
    #   - escaped char (backslash + any char)
    #   - or any char that's not a backslash or close paren
    # ...until close paren
    string_pattern = r'\((?:[^\\()]*(?:\\.[^\\()]*)*)\)'

    # Strategy: find all text-showing operators and extract their string operands
    # We look for patterns like:
    #   (text) Tj
    #   [(text) num (text)] TJ
    #   (text) '
    #   num num (text) "

    # Pattern 1: Simple Tj — single string before Tj
    # Example: (Hello World) Tj
    for match in re.finditer(r'(' + string_pattern + r')\s*Tj\b', text):
        raw_str = match.group(1)
        extracted_parts.append(_decode_pdf_string(raw_str))

    # Pattern 2: TJ array — extract all strings from the array
    # Example: [(He) -10 (llo) 20 ( Wor) (ld)] TJ
    for match in re.finditer(r'\[(.*?)\]\s*TJ\b', text, re.DOTALL):
        array_content = match.group(1)
        # Find all string literals inside the array
        for str_match in re.finditer(string_pattern, array_content):
            extracted_parts.append(_decode_pdf_string(str_match.group(0)))

    # Pattern 3: ' operator (next line + show string)
    # Example: (Hello) '
    for match in re.finditer(r'(' + string_pattern + r")\s*'", text):
        raw_str = match.group(1)
        extracted_parts.append('\n')  # ' moves to next line
        extracted_parts.append(_decode_pdf_string(raw_str))

    # Pattern 4: " operator (set spacing + next line + show string)
    # Example: 1 2 (Hello) "
    for match in re.finditer(r'(' + string_pattern + r')\s*"', text):
        raw_str = match.group(1)
        extracted_parts.append('\n')
        extracted_parts.append(_decode_pdf_string(raw_str))

    return ' '.join(extracted_parts).strip()


def _decode_pdf_string(raw: str) -> str:
    """
    Decode a PDF string literal by removing outer parens and unescaping.

    PDF strings use backslash escapes:
        \\n = newline, \\r = carriage return, \\t = tab
        \\( = literal (, \\) = literal ), \\\\ = literal backslash
        \\ddd = octal character code

    Args:
        raw: PDF string including outer parentheses, e.g. "(Hello \\(world\\))"

    Returns:
        Decoded string, e.g. "Hello (world)"
    """
    # Remove outer parentheses
    if raw.startswith('(') and raw.endswith(')'):
        raw = raw[1:-1]

    # Unescape PDF string escapes
    result = []
    i = 0
    while i < len(raw):
        if raw[i] == '\\' and i + 1 < len(raw):
            next_char = raw[i + 1]
            if next_char == 'n':
                result.append('\n')
                i += 2
            elif next_char == 'r':
                result.append('\r')
                i += 2
            elif next_char == 't':
                result.append('\t')
                i += 2
            elif next_char in ('(', ')', '\\'):
                result.append(next_char)
                i += 2
            elif next_char.isdigit():
                # Octal escape: \ddd (1-3 digits)
                octal = next_char
                i += 2
                while i < len(raw) and len(octal) < 3 and raw[i].isdigit():
                    octal += raw[i]
                    i += 1
                try:
                    result.append(chr(int(octal, 8)))
                except (ValueError, OverflowError):
                    result.append(octal)
            else:
                # Unknown escape — keep the character after backslash
                result.append(next_char)
                i += 2
        else:
            result.append(raw[i])
            i += 1

    return ''.join(result)


def _find_page_content_xrefs(doc: fitz.Document) -> dict[int, int]:
    """
    Build a mapping from content stream xref → page number.

    Each page in a PDF has a /Contents key pointing to one or more content
    stream objects. We need this mapping so that when we detect a modified
    content stream, we know which page it belongs to.

    Args:
        doc: An open PyMuPDF document

    Returns:
        Dict mapping xref number → 1-based page number.
        Example: {5: 1, 8: 2} means xref 5 is page 1's content stream.
    """
    content_to_page = {}

    for page_num in range(len(doc)):
        page = doc[page_num]
        # page.xref is the xref of the page object itself
        page_xref = page.xref

        try:
            # Get the page object definition to find /Contents references
            page_obj = doc.xref_object(page_xref)

            # /Contents can be a single reference: /Contents 5 0 R
            # or an array: /Contents [5 0 R 6 0 R]
            # We extract all referenced xref numbers

            # Pattern for single reference: /Contents N 0 R
            single = re.search(r'/Contents\s+(\d+)\s+0\s+R', page_obj)
            if single:
                content_to_page[int(single.group(1))] = page_num + 1

            # Pattern for array: /Contents [ N 0 R M 0 R ... ]
            array_match = re.search(r'/Contents\s*\[([^\]]+)\]', page_obj)
            if array_match:
                for ref in re.finditer(r'(\d+)\s+0\s+R', array_match.group(1)):
                    content_to_page[int(ref.group(1))] = page_num + 1

        except Exception:
            continue

    return content_to_page


def _detect_tool(doc: fitz.Document) -> str:
    """
    Detect the software tool used to create or modify a PDF version.

    We check two sources:
    1. XMP Toolkit (x:xmptk) — reveals the LAST editor that touched the file.
       Adobe Acrobat always writes this even if it doesn't change Producer.
    2. Producer/Creator metadata — the tool that generated the PDF.

    If XMP toolkit is present AND differs from Producer, we show both
    (e.g. "Apache FOP → Adobe Acrobat") to make the editing chain clear.

    Args:
        doc: An open PyMuPDF document

    Returns:
        Human-readable tool name, e.g. "Apache FOP Version 0.95"
        or "Apache FOP Version 0.95 → modified with Adobe Acrobat"
    """
    meta = doc.metadata
    producer = meta.get("producer", "") or ""
    creator = meta.get("creator", "") or ""
    base_tool = producer or creator or "Unknown"

    # Look for XMP toolkit — reveals the real last editor
    xmptk = ""
    try:
        for xref in range(1, doc.xref_length()):
            try:
                obj = doc.xref_object(xref)
                if obj and '/Subtype /XML' in obj:
                    stream = doc.xref_stream(xref)
                    if stream:
                        xmp_text = stream.decode('utf-8', errors='replace')
                        match = re.search(r'x:xmptk="([^"]+)"', xmp_text)
                        if match:
                            xmptk = match.group(1)
                    break
            except Exception:
                continue
    except Exception:
        pass

    if not xmptk:
        return base_tool

    # Check if XMP toolkit reveals a different editor than Producer
    # Map known XMP toolkit signatures to short names
    xmptk_lower = xmptk.lower()
    detected_editor = None
    if "adobe" in xmptk_lower:
        detected_editor = "Adobe Acrobat"
    elif "microsoft" in xmptk_lower:
        detected_editor = "Microsoft Office"
    elif "nitro" in xmptk_lower:
        detected_editor = "Nitro PDF"
    elif "foxit" in xmptk_lower:
        detected_editor = "Foxit PDF Editor"

    if not detected_editor:
        return base_tool

    # If the producer already mentions the same editor, no need to show both
    if detected_editor.split()[0].lower() in (producer or "").lower():
        return base_tool

    return f"{base_tool} → modified with {detected_editor}"


def compare_versions_by_objects(raw_bytes: bytes, eof_positions: list[int]) -> list[dict]:
    """
    Compare individual PDF objects between consecutive versions.

    This is "Approach B" for modification history. Instead of extracting
    full-page text (which fails when editors rewrite all objects), we:

    1. Open version N and version N+1 as separate PDFs
    2. Compare every xref object string between them
    3. For modified content stream objects, extract text and produce a diff

    This catches changes that page-level text extraction misses, because
    we're comparing the raw PDF objects that PyMuPDF decompresses for us.

    Args:
        raw_bytes: The raw bytes of the PDF file
        eof_positions: List of %%EOF positions (from find_eof_positions)

    Returns:
        List of diffs, same format as diff_versions() plus optional object_changes:
        [
            {
                "from_version": 1,
                "to_version": 2,
                "changes": [{"page": 1, "removed": [...], "added": [...]}],
                "object_changes": [
                    {"xref": 5, "page": 1, "type": "content_stream",
                     "removed": [...], "added": [...]},
                ]
            }
        ]
    """
    diffs = []

    for i in range(len(eof_positions) - 1):
        # Truncate raw bytes to get version N and version N+1
        old_bytes = raw_bytes[:eof_positions[i]]
        new_bytes = raw_bytes[:eof_positions[i + 1]]

        try:
            old_doc = fitz.open(stream=old_bytes, filetype="pdf")
        except Exception as e:
            logger.debug(f"Could not open version {i + 1}: {e}")
            # Can't open the old version — skip this pair
            diffs.append({
                "from_version": i + 1,
                "to_version": i + 2,
                "changes": [],
                "object_changes": [],
            })
            continue

        try:
            new_doc = fitz.open(stream=new_bytes, filetype="pdf")
        except Exception as e:
            logger.debug(f"Could not open version {i + 2}: {e}")
            old_doc.close()
            diffs.append({
                "from_version": i + 1,
                "to_version": i + 2,
                "changes": [],
                "object_changes": [],
            })
            continue

        # Skip linearization stubs: if a version has 0 pages, it's not a
        # real document version — it's just a PDF header/linearization hint.
        # Comparing it would show ALL text as "added", which is meaningless.
        if len(old_doc) == 0 or len(new_doc) == 0:
            logger.debug(
                f"Skipping version pair {i+1}->{i+2}: "
                f"old has {len(old_doc)} pages, new has {len(new_doc)} pages "
                f"(likely a linearization stub)"
            )
            old_doc.close()
            new_doc.close()
            diffs.append({
                "from_version": i + 1,
                "to_version": i + 2,
                "changes": [],
                "object_changes": [],
            })
            continue

        # =====================================================================
        # Part 1: Page-level text diff using get_text()
        # =====================================================================
        # PyMuPDF's get_text() is much more reliable than parsing raw content
        # streams ourselves. It handles font encoding, kerning, positioning,
        # etc. We use it here because both truncated PDFs opened successfully.
        changes = []
        all_pages = max(len(old_doc), len(new_doc))

        for page_idx in range(all_pages):
            old_text = ""
            new_text = ""

            if page_idx < len(old_doc):
                old_text = old_doc[page_idx].get_text("text").strip()
            if page_idx < len(new_doc):
                new_text = new_doc[page_idx].get_text("text").strip()

            if old_text == new_text:
                continue  # No changes on this page

            # Diff the page text line by line
            # Filter out whitespace-only lines BEFORE diffing.
            # PDF text extraction often has inconsistent blank lines between
            # versions (extra spaces, empty lines). If we include them,
            # the diff shows surrounding unchanged text as "moved", which
            # is noisy. We only want to see lines with real content changes.
            old_lines = [l for l in old_text.splitlines() if l.strip()]
            new_lines = [l for l in new_text.splitlines() if l.strip()]

            # Also normalize whitespace within lines: collapse multiple
            # spaces into one. PDF editors often change internal spacing
            # without changing the visible text (e.g. "Paypal  " vs "Paypal").
            old_normalized = [' '.join(l.split()) for l in old_lines]
            new_normalized = [' '.join(l.split()) for l in new_lines]

            matcher = difflib.SequenceMatcher(None, old_normalized, new_normalized)

            removed = []
            added = []
            for op, i1, i2, j1, j2 in matcher.get_opcodes():
                if op == 'equal':
                    continue
                elif op == 'delete':
                    # Use original lines (not normalized) for display
                    removed.extend(old_lines[i1:i2])
                elif op == 'insert':
                    added.extend(new_lines[j1:j2])
                elif op == 'replace':
                    removed.extend(old_lines[i1:i2])
                    added.extend(new_lines[j1:j2])

            if removed or added:
                changes.append({
                    "page": page_idx + 1,
                    "removed": removed,
                    "added": added,
                })

        # =====================================================================
        # Part 2: Object-level change inventory (metadata for detailed view)
        # =====================================================================
        # This tells us WHICH objects were modified (fonts, images, streams...)
        # but we don't use it for the text diff — get_text() handles that above.
        object_changes = []
        content_to_page = _find_page_content_xrefs(new_doc)
        old_content_to_page = _find_page_content_xrefs(old_doc)
        for xref, page in old_content_to_page.items():
            if xref not in content_to_page:
                content_to_page[xref] = page

        max_xref = max(old_doc.xref_length(), new_doc.xref_length())

        for xref in range(1, max_xref):
            try:
                old_obj = old_doc.xref_object(xref) if xref < old_doc.xref_length() else ""
                new_obj = new_doc.xref_object(xref) if xref < new_doc.xref_length() else ""
            except Exception:
                continue

            if old_obj == new_obj:
                continue

            # Classify the modified object
            page_num = content_to_page.get(xref)
            check_str = new_obj or old_obj
            obj_type = "unknown"
            if page_num and ('/Length' in check_str or not check_str):
                obj_type = "content_stream"
            elif '/Font' in check_str:
                obj_type = "font"
            elif '/Image' in check_str or '/XObject' in check_str:
                obj_type = "image"
            elif '/Type /Page' in check_str:
                obj_type = "page_definition"
            elif '/Catalog' in check_str:
                obj_type = "catalog"
            elif '/Info' in check_str:
                obj_type = "metadata"

            object_changes.append({
                "xref": xref,
                "page": page_num,
                "type": obj_type,
            })

        # Detect the tool used for each version before closing
        from_tool = _detect_tool(old_doc)
        to_tool = _detect_tool(new_doc)

        old_doc.close()
        new_doc.close()

        diffs.append({
            "from_version": i + 1,
            "to_version": i + 2,
            "from_tool": from_tool,
            "to_tool": to_tool,
            "changes": changes,
            "object_changes": object_changes,
        })

    return diffs


def extract_text_per_version(raw_bytes: bytes, eof_positions: list[int]) -> list[dict]:
    """
    Extract text from each version of the PDF by truncating at each %%EOF.

    For each version, we:
    1. Slice the raw bytes up to that version's %%EOF
    2. Open the truncated bytes with PyMuPDF
    3. Extract text from every page

    Args:
        raw_bytes: The raw bytes of the PDF file
        eof_positions: List of %%EOF positions (from find_eof_positions)

    Returns:
        List of dicts, one per version:
        [
            {"version": 1, "pages": {"1": "text on page 1", "2": "text on page 2"}},
            {"version": 2, "pages": {"1": "modified text on page 1"}},
        ]

        Returns fewer entries if some versions can't be opened (corrupted truncation).
    """
    versions = []

    for i, end_pos in enumerate(eof_positions):
        version_num = i + 1
        truncated = raw_bytes[:end_pos]

        try:
            # Open the truncated bytes as a PDF
            # fitz.open() accepts a bytes stream with filetype="pdf"
            doc = fitz.open(stream=truncated, filetype="pdf")

            # Skip versions with 0 pages — these are linearization stubs
            # (small PDF headers that don't contain any real content).
            # Comparing them would show ALL text as "added", which is useless.
            if len(doc) == 0:
                doc.close()
                logger.debug(f"Skipping version {version_num}: 0 pages (linearization stub)")
                continue

            pages_text = {}
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text("text").strip()
                pages_text[str(page_num + 1)] = text

            doc.close()

            versions.append({
                "version": version_num,
                "pages": pages_text,
            })

        except Exception as e:
            # Some truncations may not produce a valid PDF
            # (e.g., the %%EOF might be inside a comment or string)
            # We skip those silently
            logger.debug(f"Could not open version {version_num}: {e}")
            continue

    return versions


def diff_versions(versions: list[dict]) -> list[dict]:
    """
    Compare consecutive versions and produce a human-readable diff.

    For each pair of versions (N, N+1), we compare the text on each page
    and report what changed: added lines, removed lines, modified lines.

    Uses Python's difflib to compute the differences.

    Args:
        versions: List from extract_text_per_version()

    Returns:
        List of diffs:
        [
            {
                "from_version": 1,
                "to_version": 2,
                "changes": [
                    {
                        "page": 1,
                        "removed": ["old line 1", "old line 2"],
                        "added": ["new line 1"],
                    }
                ]
            }
        ]

        Empty list if there's only 1 version (no edits).
    """
    import difflib

    diffs = []

    for i in range(len(versions) - 1):
        old = versions[i]
        new = versions[i + 1]

        changes = []

        # Get all page numbers from both versions
        all_pages = sorted(
            set(old["pages"].keys()) | set(new["pages"].keys()),
            key=lambda p: int(p)
        )

        for page in all_pages:
            old_text = old["pages"].get(page, "")
            new_text = new["pages"].get(page, "")

            if old_text == new_text:
                continue  # No changes on this page

            # Split into lines for difflib
            old_lines = old_text.splitlines()
            new_lines = new_text.splitlines()

            # unified_diff gives us a clear view of what changed
            # We use SequenceMatcher for more control
            matcher = difflib.SequenceMatcher(None, old_lines, new_lines)

            removed = []
            added = []

            for op, i1, i2, j1, j2 in matcher.get_opcodes():
                if op == 'equal':
                    continue  # Lines are the same, skip
                elif op == 'delete':
                    # Lines present in old but not in new
                    removed.extend(old_lines[i1:i2])
                elif op == 'insert':
                    # Lines present in new but not in old
                    added.extend(new_lines[j1:j2])
                elif op == 'replace':
                    # Lines changed from old to new
                    removed.extend(old_lines[i1:i2])
                    added.extend(new_lines[j1:j2])

            if removed or added:
                changes.append({
                    "page": int(page),
                    "removed": removed,
                    "added": added,
                })

        diffs.append({
            "from_version": old["version"],
            "to_version": new["version"],
            "changes": changes,
        })

    return diffs


def get_modification_history(pdf_path: str) -> dict:
    """
    Main function: extract the full modification history of a PDF.

    Combines all the steps:
    1. Read raw bytes
    2. Find %%EOF positions (= versions)
    3. Extract text from each version
    4. Diff consecutive versions

    Args:
        pdf_path: Path to the PDF file

    Returns:
        dict with:
        - version_count: int (number of versions)
        - versions: list of version text data
        - diffs: list of changes between versions
        - error: str if something went wrong

    Example:
        >>> history = get_modification_history("edited_invoice.pdf")
        >>> history["version_count"]
        3
        >>> for diff in history["diffs"]:
        ...     for change in diff["changes"]:
        ...         print(f"Page {change['page']}: removed {change['removed']}")
    """
    try:
        with open(pdf_path, 'rb') as f:
            raw_bytes = f.read()

        # Step 1: Find all versions
        eof_positions = find_eof_positions(raw_bytes)

        if len(eof_positions) <= 1:
            return {
                "version_count": 1,
                "versions": [],
                "diffs": [],
                "message": "No modification history (single version PDF)"
            }

        # Step 2: Try Approach B first (object-level comparison)
        # This works even when editors like Adobe Acrobat rewrite all objects
        approach_b_diffs = []
        try:
            approach_b_diffs = compare_versions_by_objects(raw_bytes, eof_positions)
        except Exception as e:
            logger.debug(f"Approach B (object-level) failed: {e}")

        # Check if Approach B found any text changes
        approach_b_has_text = any(
            diff.get("changes") for diff in approach_b_diffs
        )

        if approach_b_has_text:
            # Approach B found meaningful text diffs — use them
            logger.debug("Using Approach B (object-level comparison) for modification history")
            return {
                "version_count": len(eof_positions),
                "versions": [],  # Not needed when using Approach B
                "diffs": approach_b_diffs,
            }

        # Step 3: Fall back to Approach A (full-page text extraction + diff)
        # This works well for simple cases where truncated PDFs are readable
        logger.debug("Falling back to Approach A (text extraction) for modification history")
        versions = extract_text_per_version(raw_bytes, eof_positions)

        if len(versions) <= 1:
            # Neither approach could extract text — but we still know there are
            # multiple versions. Return Approach B results (may have object_changes
            # even without text diffs)
            if approach_b_diffs:
                return {
                    "version_count": len(eof_positions),
                    "versions": [],
                    "diffs": approach_b_diffs,
                }
            return {
                "version_count": len(eof_positions),
                "versions": [],
                "diffs": [],
                "message": "Multiple versions detected but could not extract text from earlier versions"
            }

        # Approach A text diff
        diffs = diff_versions(versions)

        return {
            "version_count": len(eof_positions),
            "versions": versions,
            "diffs": diffs,
        }

    except Exception as e:
        logger.error(f"Error extracting modification history: {e}")
        return {
            "version_count": 0,
            "versions": [],
            "diffs": [],
            "error": str(e),
        }


# =============================================================================
# XMP TOOLKIT DETECTION
# =============================================================================

# Known XMP toolkit signatures and what software they belong to
# The xmptk attribute in XMP metadata reveals which tool last wrote the XMP block
XMP_TOOLKIT_SIGNATURES = {
    "adobe xmp core": "Adobe Acrobat",
    "adobe xmp": "Adobe Acrobat",
    "microsoft": "Microsoft Office",
    "nitro": "Nitro PDF",
    "foxit": "Foxit PDF Editor",
    "pdflib": "PDFlib",
    "itext": "iText (Java PDF library)",
}

# Known scanner software signatures (in Producer or Creator fields)
# When a document comes from a scanner and is later opened in Acrobat,
# that's a normal workflow (scan → OCR or view in Acrobat), not tampering.
SCANNER_SIGNATURES = [
    "scansnap",       # Fujitsu ScanSnap
    "pfupdf",         # Fujitsu PFU PDF engine
    "scan",           # Generic "scan" in producer/creator
    "epson",          # Epson scanners
    "canon",          # Canon scanners
    "hp scan",        # HP scanners
    "brother",        # Brother scanners
    "xerox",          # Xerox scanners
    "konica",         # Konica Minolta
    "ricoh",          # Ricoh scanners
    "kyocera",        # Kyocera scanners
    "twain",          # TWAIN scanner interface
    "wia",            # Windows Image Acquisition (scanner)
    "naps2",          # NAPS2 scanning software
    "vuescan",        # VueScan scanning software
    "readiris",       # Readiris OCR/scanner software
    "abbyy",          # ABBYY FineReader (OCR/scan)
    "paperstream",    # Fujitsu PaperStream
]


def check_xmp_toolkit_mismatch(pdf_path: str, producer: str | None, creator: str | None) -> list[Flag]:
    """
    Check if the XMP toolkit reveals a different editor than the Producer/Creator.

    PDF editors like Adobe Acrobat can modify a document without updating the
    Producer or Creator metadata fields. But they always leave their fingerprint
    in the XMP metadata block — specifically in the x:xmptk attribute.

    If the xmptk says "Adobe XMP Core" but the Producer says "wkhtmltopdf",
    it means someone opened the PDF in Acrobat and saved it.

    Args:
        pdf_path: Path to the PDF file
        producer: The Producer field from standard metadata
        creator: The Creator field from standard metadata

    Returns:
        List of flags if a mismatch is detected
    """
    flags = []

    try:
        doc = fitz.open(pdf_path)

        # Find the XMP metadata stream
        xmp_text = None
        xref_len = doc.xref_length()
        for xref in range(1, xref_len):
            try:
                obj = doc.xref_object(xref)
                if obj and '/Subtype /XML' in obj:
                    stream = doc.xref_stream(xref)
                    if stream:
                        xmp_text = stream.decode('utf-8', errors='replace')
                        break
            except Exception:
                continue

        doc.close()

        if not xmp_text:
            return flags  # No XMP metadata found

        # Extract the xmptk (XMP Toolkit) value
        # Format: x:xmptk="Adobe XMP Core 5.6-c016 91.163616, 2018/10/29"
        import re as re_mod
        match = re_mod.search(r'x:xmptk="([^"]+)"', xmp_text)
        if not match:
            return flags

        xmptk = match.group(1)

        # Check if the toolkit belongs to a known editor
        xmptk_lower = xmptk.lower()
        detected_editor = None
        for signature, editor_name in XMP_TOOLKIT_SIGNATURES.items():
            if signature in xmptk_lower:
                detected_editor = editor_name
                break

        if not detected_editor:
            return flags  # Unknown toolkit, can't determine mismatch

        # Check if this editor is different from the Producer/Creator
        # If the Producer already says "Adobe", then Acrobat in xmptk is expected
        producer_lower = (producer or "").lower()
        creator_lower = (creator or "").lower()
        editor_lower = detected_editor.lower()

        # No mismatch if producer/creator already mentions the same software
        editor_keyword = editor_lower.split()[0]  # "adobe", "microsoft", etc.
        if editor_keyword in producer_lower or editor_keyword in creator_lower:
            return flags  # No mismatch — same software

        # Mismatch detected!
        original_tool = producer or creator or "unknown"

        # Check if the original producer/creator is a scanner
        # Scanning → opening in Acrobat is a normal workflow, not tampering
        combined_lower = f"{producer_lower} {creator_lower}"
        is_scanner = any(sig in combined_lower for sig in SCANNER_SIGNATURES)

        if is_scanner:
            # Lower severity: scan → Acrobat is expected
            flags.append(Flag(
                severity="medium",
                code="STRUCT_XMP_EDITOR_MISMATCH",
                message=f"Scanned document ({original_tool}) later opened in {detected_editor}",
                details={
                    "original_producer": producer,
                    "original_creator": creator,
                    "xmp_toolkit": xmptk,
                    "detected_editor": detected_editor,
                    "is_scanned": True,
                    "explanation": f"This document was created by a scanner ({original_tool}) and "
                                  f"later opened in {detected_editor}. This is a common workflow "
                                  f"(scan → OCR or view in Acrobat) and is usually not suspicious.",
                }
            ))
        else:
            flags.append(Flag(
                severity="high",
                code="STRUCT_XMP_EDITOR_MISMATCH",
                message=f"Document created by {original_tool} but later modified with {detected_editor}",
                details={
                    "original_producer": producer,
                    "original_creator": creator,
                    "xmp_toolkit": xmptk,
                    "detected_editor": detected_editor,
                    "is_scanned": False,
                    "explanation": f"The XMP metadata reveals that {detected_editor} was used to edit "
                                  f"this document, even though the Producer field still says '{original_tool}'. "
                                  f"This is a strong indicator of post-creation editing.",
                }
            ))

    except Exception as e:
        logger.error(f"Error checking XMP toolkit: {e}")

    return flags


# =============================================================================
# STRUCTURE ANALYSIS FUNCTIONS
# =============================================================================

def has_digital_signature(pdf_path: str) -> bool:
    """
    Check if the PDF contains a digital signature field.

    Note: This only checks for PRESENCE of a signature, not validity.
    Use verify_signature_dss() to verify the signature is trusted.

    Args:
        pdf_path: Path to the PDF file

    Returns:
        True if the PDF has a digital signature field
    """
    try:
        doc = fitz.open(pdf_path)

        # Method 1: Check for signature fields in AcroForm
        for page_num in range(len(doc)):
            page = doc[page_num]
            for widget in page.widgets() or []:
                if widget.field_type_string == "Signature":
                    doc.close()
                    return True

        # Method 2: Check for signature objects in the PDF structure
        xref_len = doc.xref_length()
        for xref in range(1, xref_len):
            try:
                obj_str = doc.xref_object(xref)
                if obj_str and '/Type /Sig' in obj_str:
                    doc.close()
                    return True
                if obj_str and '/SubFilter /adbe.pkcs7' in obj_str:
                    doc.close()
                    return True
                if obj_str and '/SubFilter /ETSI' in obj_str:
                    doc.close()
                    return True
            except Exception:
                continue

        doc.close()
        return False

    except Exception as e:
        logger.error(f"Error checking for digital signature: {e}")
        return False


def verify_signature_dss(pdf_path: str) -> dict:
    """
    Verify PDF digital signature using EU DSS (Digital Signature Services) API.

    This is the official EU tool for validating electronic signatures.
    It checks against the EU Trusted Lists (LOTL).

    API: https://ec.europa.eu/digital-building-blocks/DSS/webapp-demo/services/rest/

    Args:
        pdf_path: Path to the PDF file

    Returns:
        dict with:
        - has_signature: bool
        - is_valid: bool (signature is cryptographically valid)
        - is_trusted: bool (uses EU trusted certificate - QC from LOTL)
        - signer: str (signer name if available)
        - signature_level: str (e.g., "AdESeal-QC", "QES", etc.)
        - error: str (if verification failed)
    """
    try:
        import requests
        import base64
    except ImportError:
        return {"has_signature": False, "error": "requests library not installed"}

    # Check if signature is present first
    if not has_digital_signature(pdf_path):
        return {"has_signature": False, "is_valid": False, "is_trusted": False}

    try:
        # Read PDF and encode as base64
        with open(pdf_path, 'rb') as f:
            pdf_bytes = f.read()
        pdf_base64 = base64.b64encode(pdf_bytes).decode('utf-8')

        # DSS REST API endpoint for validation
        dss_url = "https://ec.europa.eu/digital-building-blocks/DSS/webapp-demo/services/rest/validation/validateSignature"

        # Request payload
        payload = {
            "signedDocument": {
                "bytes": pdf_base64,
                "name": "document.pdf"
            }
        }

        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        response = requests.post(dss_url, json=payload, headers=headers, timeout=30)

        if response.status_code == 200:
            result = response.json()

            # Parse SimpleReport (cleaner format than raw response)
            simple_report = result.get("SimpleReport", {})
            valid_count = simple_report.get("ValidSignaturesCount", 0)
            total_count = simple_report.get("SignaturesCount", 0)

            # Get signatures from SimpleReport
            signatures = simple_report.get("signatureOrTimestampOrEvidenceRecord", [])

            if not signatures:
                return {
                    "has_signature": True,
                    "is_valid": None,
                    "is_trusted": False,
                    "unverifiable": True,
                    "error": "No signatures found in DSS response"
                }

            # Check first signature
            sig_wrapper = signatures[0]
            sig = sig_wrapper.get("Signature", {})

            signer_name = sig.get("SignedBy", "")
            signing_time = sig.get("SigningTime", "")

            # Get signature level (e.g., "AdESeal-QC", "QES", "AdES", etc.)
            level_info = sig.get("SignatureLevel", {})
            if isinstance(level_info, dict):
                level_value = level_info.get("value", "")
                level_desc = level_info.get("description", "")
            else:
                level_value = str(level_info)
                level_desc = ""

            # Determine trust level based on signature level
            # QC = Qualified Certificate (from EU Trusted List)
            # QES = Qualified Electronic Signature
            # AdESeal-QC = Advanced Electronic Seal with Qualified Certificate
            has_qc = "QC" in level_value or "QES" in level_value

            # Check if fully valid (PASSED) or indeterminate
            # Indeterminate with QC is still trustworthy (certificate might just be expired)
            is_fully_valid = valid_count > 0

            # A signature is "trusted" if it uses a Qualified Certificate from EU list
            # Even if "Indeterminate" (e.g., expired cert), QC means it was issued by trusted CA
            is_trusted = has_qc

            # "Valid" means the signature is cryptographically correct
            # Even Indeterminate signatures are valid if they have QC
            is_valid = is_fully_valid or has_qc

            return {
                "has_signature": True,
                "is_valid": is_valid,
                "is_trusted": is_trusted,
                "is_fully_valid": is_fully_valid,
                "signer": signer_name,
                "signing_time": signing_time,
                "signature_level": level_value,
                "signature_level_description": level_desc,
                "has_qualified_certificate": has_qc,
            }

        else:
            return {
                "has_signature": True,
                "is_valid": False,
                "is_trusted": False,
                "error": f"DSS API error: HTTP {response.status_code}"
            }

    except requests.Timeout:
        return {
            "has_signature": True,
            "is_valid": False,
            "is_trusted": False,
            "error": "DSS API timeout"
        }
    except requests.RequestException as e:
        return {
            "has_signature": True,
            "is_valid": False,
            "is_trusted": False,
            "error": f"DSS API request failed: {e}"
        }
    except Exception as e:
        return {
            "has_signature": True,
            "is_valid": False,
            "is_trusted": False,
            "error": f"Signature verification error: {e}"
        }


def count_incremental_updates(pdf_path: str) -> int:
    """
    Count the number of incremental updates (revisions) in a PDF.

    Each time a PDF is edited and saved, a new "%%EOF" marker is added.
    A clean PDF has exactly 1 EOF. Multiple EOFs = multiple edits.

    Args:
        pdf_path: Path to the PDF file

    Returns:
        Number of EOF markers found (1 = clean, >1 = edited)
    """
    try:
        with open(pdf_path, 'rb') as f:
            content = f.read()

        # Count %%EOF markers
        # Each incremental update ends with %%EOF
        eof_count = content.count(b'%%EOF')

        return eof_count
    except Exception as e:
        logger.error(f"Error counting incremental updates: {e}")
        return 1  # Assume clean if we can't read


def check_incremental_updates(pdf_path: str, verify_signatures: bool = True) -> list[Flag]:
    """
    Check if the PDF has been edited (has incremental updates).

    If a TRUSTED digital signature is present (verified via EU DSS API),
    1 incremental update is expected and legitimate.
    An untrusted or invalid signature does NOT excuse incremental updates.

    Args:
        pdf_path: Path to the PDF file
        verify_signatures: Whether to verify signatures via DSS API

    Returns:
        List of flags if suspicious updates detected
    """
    flags = []

    eof_count = count_incremental_updates(pdf_path)

    if eof_count <= 1:
        return flags  # No incremental updates, clean PDF

    edits = eof_count - 1

    # Check for digital signature
    has_signature = has_digital_signature(pdf_path)
    signature_trusted = False
    signature_info = {}

    if has_signature and verify_signatures:
        # Verify signature via EU DSS API
        signature_info = verify_signature_dss(pdf_path)
        signature_trusted = signature_info.get("is_trusted", False)

        # Add flag about signature status
        signer = signature_info.get("signer", "Unknown")
        level = signature_info.get("signature_level", "")

        if signature_info.get("is_trusted"):
            # Signature uses Qualified Certificate from EU Trusted List
            if signature_info.get("is_fully_valid"):
                # Fully validated
                flags.append(Flag(
                    severity="low",  # Informational - excellent signature
                    code="STRUCT_SIGNATURE_TRUSTED",
                    message=f"Document has EU trusted signature: {signer} ({level})",
                    details=signature_info
                ))
            else:
                # QC but not fully valid (e.g., cert expired but was valid at signing time)
                flags.append(Flag(
                    severity="low",  # Still trustworthy - QC from EU list
                    code="STRUCT_SIGNATURE_TRUSTED_EXPIRED",
                    message=f"Document has EU trusted signature (certificate may be expired): {signer}",
                    details=signature_info
                ))
        elif signature_info.get("is_valid"):
            # Valid signature but not from EU trusted list
            flags.append(Flag(
                severity="medium",
                code="STRUCT_SIGNATURE_NOT_TRUSTED",
                message=f"Document has signature but NOT from EU trusted list: {signer}",
                details=signature_info
            ))
        elif signature_info.get("unverifiable"):
            # Signature present but couldn't be verified
            flags.append(Flag(
                severity="medium",
                code="STRUCT_SIGNATURE_UNVERIFIABLE",
                message="Document has signature but format not recognized by EU DSS",
                details=signature_info
            ))
        elif signature_info.get("has_signature"):
            # Signature is invalid
            flags.append(Flag(
                severity="high",
                code="STRUCT_SIGNATURE_INVALID",
                message="Document has INVALID digital signature",
                details=signature_info
            ))

    # Only trusted signatures excuse 1 incremental update
    if signature_trusted and edits == 1:
        # Trusted signature + 1 update = legitimate, don't flag edits
        return flags

    # Calculate effective edits (subtract 1 if trusted signature)
    effective_edits = edits - 1 if signature_trusted else edits

    if effective_edits <= 0:
        return flags

    # Severity based on number of edits
    if effective_edits >= 3:
        severity = "critical"
        message = f"PDF has been edited {effective_edits} times (very suspicious)"
    elif effective_edits == 2:
        severity = "high"
        message = f"PDF has been edited {effective_edits} times"
    else:
        severity = "medium"
        message = f"PDF has {effective_edits} incremental update(s)"

    # Add context about untrusted signature if present
    if has_signature and not signature_trusted:
        message += " (signature present but NOT trusted)"

    flags.append(Flag(
        severity=severity,
        code="STRUCT_INCREMENTAL_UPDATES",
        message=message,
        details={
            "eof_count": eof_count,
            "edit_count": edits,
            "has_signature": has_signature,
            "signature_trusted": signature_trusted,
            "effective_edits": effective_edits,
            "explanation": "Each edit adds a new version to the PDF. "
                          "Only EU-trusted digital signatures excuse 1 update."
        }
    ))

    return flags


def check_javascript(pdf_path: str) -> list[Flag]:
    """
    Check if the PDF contains JavaScript.

    JavaScript in a PDF is very suspicious for invoices/certificates.
    It could be used for:
    - Malware delivery
    - Dynamic content modification
    - Phishing attacks

    Args:
        pdf_path: Path to the PDF file

    Returns:
        List of flags if JavaScript detected
    """
    flags = []

    try:
        doc = fitz.open(pdf_path)

        # Check for JavaScript in the document
        # PyMuPDF can extract JS from various locations

        # Method 1: Check document-level JavaScript
        js_found = False
        js_locations = []

        # Check PDF catalog for JavaScript
        try:
            # Get the PDF trailer/catalog
            xref_len = doc.xref_length()

            for xref in range(1, xref_len):
                try:
                    obj_str = doc.xref_object(xref)
                    if obj_str:
                        # Look for JavaScript indicators
                        if '/JavaScript' in obj_str or '/JS' in obj_str:
                            js_found = True
                            js_locations.append(f"xref {xref}")
                except Exception:
                    continue
        except Exception as e:
            logger.debug(f"Error checking xref for JS: {e}")

        # Method 2: Check for JavaScript in annotations
        for page_num in range(len(doc)):
            page = doc[page_num]

            # Check annotations
            for annot in page.annots() or []:
                annot_info = annot.info
                if annot_info:
                    # Check for JavaScript actions
                    if 'javascript' in str(annot_info).lower():
                        js_found = True
                        js_locations.append(f"annotation on page {page_num + 1}")

        doc.close()

        if js_found:
            flags.append(Flag(
                severity="critical",
                code="STRUCT_JAVASCRIPT_DETECTED",
                message="PDF contains JavaScript code (very suspicious for documents)",
                details={
                    "locations": js_locations,
                    "warning": "JavaScript in PDFs can be used for malware or phishing. "
                              "Legitimate invoices never contain JavaScript."
                }
            ))

    except Exception as e:
        logger.error(f"Error checking for JavaScript: {e}")

    return flags


def check_hidden_annotations(pdf_path: str) -> list[Flag]:
    """
    Check for hidden or suspicious annotations in the PDF.

    Annotations can contain:
    - Hidden comments (review history)
    - Invisible links
    - Form fields
    - Redactions (covered content)

    Args:
        pdf_path: Path to the PDF file

    Returns:
        List of flags if suspicious annotations found
    """
    flags = []

    try:
        doc = fitz.open(pdf_path)

        hidden_annots = []
        suspicious_annots = []

        for page_num in range(len(doc)):
            page = doc[page_num]

            for annot in page.annots() or []:
                annot_type = annot.type[1]  # Get annotation type name

                # Check for hidden annotations (opacity = 0 or invisible flag)
                if annot.opacity == 0:
                    hidden_annots.append({
                        "page": page_num + 1,
                        "type": annot_type,
                        "reason": "opacity is 0 (invisible)"
                    })

                # Check for suspicious annotation types
                suspicious_types = ['FileAttachment', 'Sound', 'Movie', 'Screen', 'RichMedia']
                if annot_type in suspicious_types:
                    suspicious_annots.append({
                        "page": page_num + 1,
                        "type": annot_type,
                        "reason": f"suspicious type: {annot_type}"
                    })

        doc.close()

        if hidden_annots:
            flags.append(Flag(
                severity="high",
                code="STRUCT_HIDDEN_ANNOTATIONS",
                message=f"PDF contains {len(hidden_annots)} hidden annotation(s)",
                details={
                    "annotations": hidden_annots,
                    "explanation": "Hidden annotations may contain concealed information."
                }
            ))

        if suspicious_annots:
            flags.append(Flag(
                severity="high",
                code="STRUCT_SUSPICIOUS_ANNOTATIONS",
                message=f"PDF contains suspicious annotation types",
                details={
                    "annotations": suspicious_annots,
                    "explanation": "These annotation types are unusual for invoices."
                }
            ))

    except Exception as e:
        logger.error(f"Error checking annotations: {e}")

    return flags


def check_embedded_files(pdf_path: str) -> list[Flag]:
    """
    Check for embedded files in the PDF.

    Embedded files can be used to hide:
    - Malware
    - Additional documents
    - Executable code

    Args:
        pdf_path: Path to the PDF file

    Returns:
        List of flags if embedded files found
    """
    flags = []

    try:
        doc = fitz.open(pdf_path)

        # Get embedded files
        embedded_count = doc.embfile_count()

        if embedded_count > 0:
            embedded_files = []

            for i in range(embedded_count):
                info = doc.embfile_info(i)
                embedded_files.append({
                    "name": info.get("name", "unknown"),
                    "size": info.get("size", 0),
                })

            # Determine severity based on file types
            dangerous_extensions = ['.exe', '.js', '.vbs', '.bat', '.cmd', '.ps1', '.dll']
            has_dangerous = any(
                any(f["name"].lower().endswith(ext) for ext in dangerous_extensions)
                for f in embedded_files
            )

            if has_dangerous:
                severity = "critical"
                message = "PDF contains embedded executable files (malware risk!)"
            else:
                severity = "high"
                message = f"PDF contains {embedded_count} embedded file(s)"

            flags.append(Flag(
                severity=severity,
                code="STRUCT_EMBEDDED_FILES",
                message=message,
                details={
                    "file_count": embedded_count,
                    "files": embedded_files,
                    "warning": "Embedded files in invoices are suspicious."
                }
            ))

        doc.close()

    except Exception as e:
        logger.error(f"Error checking embedded files: {e}")

    return flags


def check_acroform(pdf_path: str) -> list[Flag]:
    """
    Check for AcroForm (interactive forms) in the PDF.

    While forms are legitimate in some contexts, they're suspicious
    in invoices because they can be used to:
    - Collect data (phishing)
    - Execute JavaScript
    - Modify displayed content

    Note: Signature fields are excluded - they are legitimate for signed documents.

    Args:
        pdf_path: Path to the PDF file

    Returns:
        List of flags if forms detected
    """
    flags = []

    try:
        doc = fitz.open(pdf_path)

        # Check for form fields
        form_fields = []
        signature_fields = []

        for page_num in range(len(doc)):
            page = doc[page_num]

            # Get widgets (form fields)
            widgets = page.widgets()
            if widgets:
                for widget in widgets:
                    field_info = {
                        "page": page_num + 1,
                        "type": widget.field_type_string,
                        "name": widget.field_name or "unnamed",
                    }

                    # Separate signature fields from other form fields
                    if widget.field_type_string == "Signature":
                        signature_fields.append(field_info)
                    else:
                        form_fields.append(field_info)

        doc.close()

        # Only flag non-signature form fields
        # Signature fields are legitimate for digitally signed documents
        if form_fields:
            flags.append(Flag(
                severity="medium",
                code="STRUCT_ACROFORM_DETECTED",
                message=f"PDF contains {len(form_fields)} interactive form field(s)",
                details={
                    "fields": form_fields[:10],  # Limit to first 10
                    "total_count": len(form_fields),
                    "note": "Interactive forms are unusual in invoices."
                }
            ))

    except Exception as e:
        logger.error(f"Error checking AcroForm: {e}")

    return flags


def check_object_streams(pdf_path: str, has_trusted_signature: bool = False) -> list[Flag]:
    """
    Check for suspicious patterns in PDF object streams.

    Look for:
    - Deleted objects that are still in the file
    - Unusual object counts
    - Signs of manipulation

    Args:
        pdf_path: Path to the PDF file
        has_trusted_signature: If True, allows more deleted objects (signing creates them)

    Returns:
        List of flags if suspicious patterns found
    """
    flags = []

    try:
        with open(pdf_path, 'rb') as f:
            content = f.read()

        # Count "obj" declarations vs "endobj"
        obj_count = len(re.findall(rb'\d+\s+\d+\s+obj', content))
        endobj_count = content.count(b'endobj')

        # Look for free objects (deleted but still present)
        # In xref table, 'f' means free (deleted)
        free_objects = len(re.findall(rb'\d{10}\s+\d{5}\s+f', content))

        # Threshold depends on whether document has a trusted signature
        # Signed documents: signing process creates deleted objects (normal up to ~15)
        # Unsigned documents: should have minimal deleted objects (suspicious if > 3)
        if has_trusted_signature:
            threshold = 15  # Signing process creates objects
            explanation = ("Deleted objects may contain previous versions of content. "
                          "For signed documents, some deleted objects are normal.")
        else:
            threshold = 10  # Some PDF generators create/delete temp objects normally
            explanation = ("Deleted objects may contain previous versions of content. "
                          "An unsigned document should have minimal deleted objects.")

        if free_objects > threshold:
            flags.append(Flag(
                severity="medium",
                code="STRUCT_DELETED_OBJECTS",
                message=f"PDF contains {free_objects} deleted objects (ghost data)",
                details={
                    "free_objects": free_objects,
                    "threshold": threshold,
                    "has_trusted_signature": has_trusted_signature,
                    "explanation": explanation,
                }
            ))

    except Exception as e:
        logger.error(f"Error checking object streams: {e}")

    return flags


# =============================================================================
# SEVERITY POINTS
# =============================================================================

SEVERITY_POINTS = {
    "low": 5,
    "medium": 15,
    "high": 30,
    "critical": 50,
}


# =============================================================================
# MAIN ANALYSIS FUNCTION
# =============================================================================

def analyze_structure(pdf_data: PDFData, verify_signatures: bool = True) -> ModuleResult:
    """
    Analyze PDF internal structure for signs of manipulation.

    Args:
        pdf_data: Extracted PDF data
        verify_signatures: Whether to verify digital signatures via EU DSS API
                          (requires internet, set False for offline use)

    Returns:
        ModuleResult with score, flags, and confidence
    """
    all_flags = []

    # First, check for trusted signature (affects other checks)
    has_trusted_signature = False
    if verify_signatures and has_digital_signature(pdf_data.file_path):
        sig_info = verify_signature_dss(pdf_data.file_path)
        has_trusted_signature = sig_info.get("is_trusted", False)

    # Run all structure checks
    all_flags.extend(check_incremental_updates(pdf_data.file_path, verify_signatures))
    all_flags.extend(check_javascript(pdf_data.file_path))
    all_flags.extend(check_hidden_annotations(pdf_data.file_path))
    all_flags.extend(check_embedded_files(pdf_data.file_path))
    all_flags.extend(check_acroform(pdf_data.file_path))
    all_flags.extend(check_object_streams(pdf_data.file_path, has_trusted_signature))

    # Check creation vs modification time gap
    # A legitimate document is generated once — any modification is suspicious
    all_flags.extend(check_dates(
        pdf_data.metadata.creation_date,
        pdf_data.metadata.mod_date
    ))

    # Check if XMP toolkit reveals a hidden editor
    all_flags.extend(check_xmp_toolkit_mismatch(
        pdf_data.file_path,
        pdf_data.metadata.producer,
        pdf_data.metadata.creator,
    ))

    # Calculate score
    score = 100
    for flag in all_flags:
        score -= SEVERITY_POINTS[flag.severity]
    score = max(0, score)

    # High confidence - we can reliably analyze PDF structure
    confidence = 0.95

    return ModuleResult(
        module="structure",
        flags=all_flags,
        score=score,
        confidence=confidence,
    )
